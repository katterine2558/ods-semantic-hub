{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katterine2558/ods-semantic-hub/blob/main/ods_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOLUCIÓN MICROPROYECTO 2\n",
        "\n",
        "Por: *Leonardo Almanza y Katerine Arias*"
      ],
      "metadata": {
        "id": "EfAC-CLZ0So1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importar librerías\n",
        "En esta etapa inicial se realiza la importación de las librerías esenciales para desarrollar una solución automatizada de clasificación de textos según los 17 Objetivos de Desarrollo Sostenible (ODS). Se incluyen herramientas fundamentales para manipulación y análisis de datos (Pandas, NumPy), procesamiento de lenguaje natural (NLTK, word_tokenize, stopwords, PorterStemmer), extracción de características textuales (CountVectorizer, TfidfVectorizer), implementación de algoritmos de machine learning supervisado (Naive Bayes, Regresión Logística) y  técnicas de reducción de dimensionalidad (PCA, TruncatedSVD). Estas herramientas permiten transformar textos  en representaciones vectoriales mediante el esquema de bolsa de palabras (BOW) con pesado TF-IDF, aplicar técnicas de reducción de dimensionalidad para manejar la alta dimensionalidad del espacio de entrada, y construir modelos de clasificación automática."
      ],
      "metadata": {
        "id": "UNXWLN8717GW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K0PZ5vaOWFGg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "# NLTK para procesamiento de texto\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ]
    }
  ]
}